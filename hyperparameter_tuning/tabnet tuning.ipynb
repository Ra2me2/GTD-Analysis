{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression,Ridge\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error,r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "from pre_processing import preprocess_data\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    dataset = pd.read_excel(r\"globalterrorismdb_2021Jan-June_1222dist.xlsx\") # 2021-2021 June\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success</th>\n",
       "      <th>gname_freq</th>\n",
       "      <th>city_freq</th>\n",
       "      <th>country_freq</th>\n",
       "      <th>attacktype1_score</th>\n",
       "      <th>targtype1_score</th>\n",
       "      <th>weaptype1_score</th>\n",
       "      <th>gname_score</th>\n",
       "      <th>country_score</th>\n",
       "      <th>city_score</th>\n",
       "      <th>...</th>\n",
       "      <th>nkill_likelihood_score</th>\n",
       "      <th>region_3</th>\n",
       "      <th>region_5</th>\n",
       "      <th>region_6</th>\n",
       "      <th>region_8</th>\n",
       "      <th>region_9</th>\n",
       "      <th>region_10</th>\n",
       "      <th>region_11</th>\n",
       "      <th>region_12</th>\n",
       "      <th>nkill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.167228</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.121429</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.096521</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.159371</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.121429</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.096521</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.093154</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   success  gname_freq  city_freq  country_freq  attacktype1_score  \\\n",
       "0      1.0    0.228571   0.066667      0.167228              0.875   \n",
       "1      1.0    0.121429   0.033333      0.096521              0.500   \n",
       "2      1.0    0.000000   0.033333      0.159371              0.875   \n",
       "3      1.0    0.121429   0.033333      0.096521              0.875   \n",
       "4      1.0    0.000000   0.033333      0.093154              0.875   \n",
       "\n",
       "   targtype1_score  weaptype1_score  gname_score  country_score  city_score  \\\n",
       "0         1.000000         0.857143     0.977778       0.948718    0.123077   \n",
       "1         0.842105         0.857143     0.911111       0.871795    0.030769   \n",
       "2         0.894737         0.857143     0.000000       0.641026    0.015385   \n",
       "3         0.894737         0.857143     0.911111       0.871795    0.092308   \n",
       "4         1.000000         0.857143     0.022222       0.743590    0.030769   \n",
       "\n",
       "   ...  nkill_likelihood_score  region_3  region_5  region_6  region_8  \\\n",
       "0  ...                0.589934       0.0       0.0       0.0       0.0   \n",
       "1  ...                0.347526       0.0       0.0       0.0       0.0   \n",
       "2  ...                0.477050       0.0       0.0       1.0       0.0   \n",
       "3  ...                0.503175       0.0       0.0       0.0       0.0   \n",
       "4  ...                0.543654       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   region_9  region_10  region_11  region_12  nkill  \n",
       "0       0.0        1.0        0.0        0.0    5.0  \n",
       "1       0.0        0.0        1.0        0.0    1.0  \n",
       "2       0.0        0.0        0.0        0.0    0.0  \n",
       "3       0.0        0.0        1.0        0.0    6.0  \n",
       "4       0.0        1.0        0.0        0.0    1.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_data()\n",
    "X, y, dataset = preprocess_data(dataset)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) TabNet\n",
    "## Hyperparameter Tuning and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 44.52012| val_rmse: 7.11181 |  0:00:21s\n",
      "epoch 1  | loss: 40.02954| val_rmse: 7.03802 |  0:00:36s\n",
      "epoch 2  | loss: 35.6399 | val_rmse: 6.27565 |  0:00:54s\n",
      "epoch 3  | loss: 30.95694| val_rmse: 6.79133 |  0:01:10s\n",
      "epoch 4  | loss: 29.27898| val_rmse: 5.34931 |  0:01:27s\n",
      "epoch 5  | loss: 26.85812| val_rmse: 6.86841 |  0:01:46s\n",
      "epoch 6  | loss: 24.44915| val_rmse: 6.72198 |  0:02:02s\n",
      "epoch 7  | loss: 24.74707| val_rmse: 4.88494 |  0:02:19s\n",
      "epoch 8  | loss: 24.47092| val_rmse: 5.28352 |  0:02:37s\n",
      "epoch 9  | loss: 22.90403| val_rmse: 5.42474 |  0:02:55s\n",
      "epoch 10 | loss: 22.11533| val_rmse: 6.45587 |  0:03:13s\n",
      "epoch 11 | loss: 22.78002| val_rmse: 5.34018 |  0:03:28s\n",
      "epoch 12 | loss: 20.97734| val_rmse: 3.91207 |  0:03:44s\n",
      "epoch 13 | loss: 18.74327| val_rmse: 3.49495 |  0:04:00s\n",
      "epoch 14 | loss: 19.58238| val_rmse: 3.36599 |  0:04:19s\n",
      "epoch 15 | loss: 18.98585| val_rmse: 3.00902 |  0:04:38s\n",
      "epoch 16 | loss: 20.61077| val_rmse: 2.97067 |  0:04:58s\n",
      "epoch 17 | loss: 19.15022| val_rmse: 3.58833 |  0:05:21s\n",
      "epoch 18 | loss: 20.22049| val_rmse: 2.93691 |  0:05:45s\n",
      "epoch 19 | loss: 18.87623| val_rmse: 3.74494 |  0:06:05s\n",
      "epoch 20 | loss: 18.89376| val_rmse: 3.11766 |  0:06:29s\n",
      "epoch 21 | loss: 19.16224| val_rmse: 3.30937 |  0:06:51s\n",
      "epoch 22 | loss: 18.85354| val_rmse: 2.97092 |  0:07:10s\n",
      "epoch 23 | loss: 18.72452| val_rmse: 3.05779 |  0:07:32s\n",
      "epoch 24 | loss: 19.4039 | val_rmse: 3.6491  |  0:07:51s\n",
      "epoch 25 | loss: 19.50342| val_rmse: 3.07995 |  0:08:11s\n",
      "epoch 26 | loss: 18.92416| val_rmse: 3.15154 |  0:08:34s\n",
      "epoch 27 | loss: 18.22444| val_rmse: 3.06449 |  0:08:55s\n",
      "epoch 28 | loss: 18.38446| val_rmse: 2.99779 |  0:09:15s\n",
      "epoch 29 | loss: 17.78361| val_rmse: 3.47565 |  0:09:34s\n",
      "epoch 30 | loss: 17.17081| val_rmse: 3.65771 |  0:09:56s\n",
      "epoch 31 | loss: 19.69966| val_rmse: 2.95957 |  0:10:16s\n",
      "epoch 32 | loss: 17.31652| val_rmse: 4.0181  |  0:10:39s\n",
      "epoch 33 | loss: 16.89037| val_rmse: 3.90776 |  0:11:04s\n",
      "                                                      \n",
      "Early stopping occurred at epoch 33 with best_epoch = 18 and best_val_rmse = 2.93691\n",
      "  0%|          | 0/15 [11:05<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 1/15 [11:06<2:35:37, 666.94s/trial, best loss: 3.907758157350823]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 42.46979| val_rmse: 7.49564 |  0:00:23s                          \n",
      "epoch 1  | loss: 35.22186| val_rmse: 7.34564 |  0:00:44s                          \n",
      "epoch 2  | loss: 31.32014| val_rmse: 7.26213 |  0:01:04s                          \n",
      "epoch 3  | loss: 28.80977| val_rmse: 7.36305 |  0:01:23s                          \n",
      "epoch 4  | loss: 30.22053| val_rmse: 7.05032 |  0:01:42s                          \n",
      "epoch 5  | loss: 28.727  | val_rmse: 9.43821 |  0:02:03s                          \n",
      "epoch 6  | loss: 37.64225| val_rmse: 7.51735 |  0:02:28s                          \n",
      "epoch 7  | loss: 35.08614| val_rmse: 6.74595 |  0:02:53s                          \n",
      "epoch 8  | loss: 30.47883| val_rmse: 13.508  |  0:03:19s                          \n",
      "epoch 9  | loss: 31.67772| val_rmse: 6.96439 |  0:03:45s                          \n",
      "epoch 10 | loss: 28.94419| val_rmse: 7.77224 |  0:04:11s                          \n",
      "epoch 11 | loss: 31.71226| val_rmse: 8.07159 |  0:04:37s                          \n",
      "epoch 12 | loss: 32.55248| val_rmse: 7.33695 |  0:05:12s                          \n",
      "epoch 13 | loss: 44.06134| val_rmse: 9.86044 |  0:05:38s                          \n",
      "epoch 14 | loss: 45.06505| val_rmse: 6.87208 |  0:05:59s                          \n",
      "epoch 15 | loss: 42.64929| val_rmse: 7.28991 |  0:06:17s                          \n",
      "epoch 16 | loss: 40.26314| val_rmse: 6.6647  |  0:06:37s                          \n",
      "epoch 17 | loss: 29.28148| val_rmse: 4.72114 |  0:06:56s                          \n",
      "epoch 18 | loss: 31.00125| val_rmse: 7.37739 |  0:07:13s                          \n",
      "epoch 19 | loss: 26.99876| val_rmse: 5.64968 |  0:07:30s                          \n",
      "epoch 20 | loss: 27.93134| val_rmse: 5.98707 |  0:07:46s                          \n",
      "epoch 21 | loss: 31.42731| val_rmse: 7.82074 |  0:08:02s                          \n",
      "epoch 22 | loss: 40.4442 | val_rmse: 7.24216 |  0:08:18s                          \n",
      "epoch 23 | loss: 42.19731| val_rmse: 6.90557 |  0:08:33s                          \n",
      "epoch 24 | loss: 30.9357 | val_rmse: 7.9244  |  0:08:48s                          \n",
      "epoch 25 | loss: 32.42989| val_rmse: 7.35565 |  0:09:04s                          \n",
      "epoch 26 | loss: 28.2282 | val_rmse: 6.17528 |  0:09:16s                          \n",
      "epoch 27 | loss: 27.31248| val_rmse: 6.98405 |  0:09:30s                          \n",
      "epoch 28 | loss: 33.2559 | val_rmse: 7.11148 |  0:09:45s                          \n",
      "epoch 29 | loss: 26.99657| val_rmse: 5.70165 |  0:10:00s                          \n",
      "epoch 30 | loss: 29.97883| val_rmse: 13.59603|  0:10:15s                          \n",
      "epoch 31 | loss: 31.29356| val_rmse: 7.75909 |  0:10:30s                          \n",
      "epoch 32 | loss: 30.45986| val_rmse: 6.33556 |  0:10:44s                          \n",
      "                                                                                  \n",
      "Early stopping occurred at epoch 32 with best_epoch = 17 and best_val_rmse = 4.72114\n",
      "  7%|â–‹         | 1/15 [21:51<2:35:37, 666.94s/trial, best loss: 3.907758157350823]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–Ž        | 2/15 [21:53<2:21:53, 654.87s/trial, best loss: 3.907758157350823]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 52.68773| val_rmse: 7.47257 |  0:00:18s                          \n",
      "epoch 1  | loss: 45.74204| val_rmse: 7.67541 |  0:00:37s                          \n",
      "epoch 2  | loss: 43.26756| val_rmse: 7.39057 |  0:00:56s                          \n",
      "epoch 3  | loss: 41.18277| val_rmse: 7.30956 |  0:01:15s                          \n",
      "epoch 4  | loss: 39.03738| val_rmse: 7.92848 |  0:01:34s                          \n",
      "epoch 5  | loss: 39.21744| val_rmse: 7.37697 |  0:01:52s                          \n",
      "epoch 6  | loss: 40.51704| val_rmse: 7.08259 |  0:02:11s                          \n",
      "epoch 7  | loss: 37.76796| val_rmse: 6.57183 |  0:02:30s                          \n",
      "epoch 8  | loss: 35.62853| val_rmse: 6.6441  |  0:02:49s                          \n",
      "epoch 9  | loss: 32.69339| val_rmse: 6.05404 |  0:03:08s                          \n",
      "epoch 10 | loss: 26.91585| val_rmse: 7.70093 |  0:03:27s                          \n",
      "epoch 11 | loss: 22.37024| val_rmse: 4.26296 |  0:03:47s                          \n",
      "epoch 12 | loss: 24.60797| val_rmse: 6.72694 |  0:04:06s                          \n",
      "epoch 13 | loss: 27.0821 | val_rmse: 4.33048 |  0:04:25s                          \n",
      "epoch 14 | loss: 29.09247| val_rmse: 3.45765 |  0:04:44s                          \n",
      "epoch 15 | loss: 24.262  | val_rmse: 4.13368 |  0:05:03s                          \n",
      "epoch 16 | loss: 24.95101| val_rmse: 4.01378 |  0:05:21s                          \n",
      "epoch 17 | loss: 23.43261| val_rmse: 4.40914 |  0:05:40s                          \n",
      "epoch 18 | loss: 21.76457| val_rmse: 4.6114  |  0:05:59s                          \n",
      "epoch 19 | loss: 23.38087| val_rmse: 5.46897 |  0:06:17s                          \n",
      "epoch 20 | loss: 20.48188| val_rmse: 4.23511 |  0:06:36s                          \n",
      "epoch 21 | loss: 21.88802| val_rmse: 4.79623 |  0:06:55s                          \n",
      "epoch 22 | loss: 21.90992| val_rmse: 6.43333 |  0:07:13s                          \n",
      "epoch 23 | loss: 21.83093| val_rmse: 5.28184 |  0:07:32s                          \n",
      "epoch 24 | loss: 24.23897| val_rmse: 3.76643 |  0:07:50s                          \n",
      "epoch 25 | loss: 23.18638| val_rmse: 4.46386 |  0:08:09s                          \n",
      "epoch 26 | loss: 23.38986| val_rmse: 4.83672 |  0:08:28s                          \n",
      "epoch 27 | loss: 22.74973| val_rmse: 7.27642 |  0:08:46s                          \n",
      "epoch 28 | loss: 22.71267| val_rmse: 4.35682 |  0:09:04s                          \n",
      "epoch 29 | loss: 22.21136| val_rmse: 6.67612 |  0:09:23s                          \n",
      "                                                                                  \n",
      "Early stopping occurred at epoch 29 with best_epoch = 14 and best_val_rmse = 3.45765\n",
      " 13%|â–ˆâ–Ž        | 2/15 [31:17<2:21:53, 654.87s/trial, best loss: 3.907758157350823]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 3/15 [31:20<2:02:55, 614.65s/trial, best loss: 3.907758157350823]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 46.6845 | val_rmse: 7.34345 |  0:00:17s                          \n",
      "epoch 1  | loss: 38.96864| val_rmse: 7.36922 |  0:00:35s                          \n",
      "epoch 2  | loss: 37.18931| val_rmse: 7.29388 |  0:00:52s                          \n",
      "epoch 3  | loss: 34.80742| val_rmse: 7.06651 |  0:01:10s                          \n",
      "epoch 4  | loss: 36.17383| val_rmse: 7.08279 |  0:01:28s                          \n",
      "epoch 5  | loss: 36.6327 | val_rmse: 6.89798 |  0:01:45s                          \n",
      "epoch 6  | loss: 27.4861 | val_rmse: 5.12826 |  0:02:02s                          \n",
      "epoch 7  | loss: 29.74421| val_rmse: 5.77529 |  0:02:20s                          \n",
      "epoch 8  | loss: 28.96998| val_rmse: 5.41032 |  0:02:37s                          \n",
      "epoch 9  | loss: 26.04263| val_rmse: 5.19904 |  0:02:54s                          \n",
      "epoch 10 | loss: 25.22872| val_rmse: 5.2364  |  0:03:12s                          \n",
      "epoch 11 | loss: 23.6226 | val_rmse: 4.61802 |  0:03:29s                          \n",
      "epoch 12 | loss: 24.22719| val_rmse: 5.04259 |  0:03:46s                          \n",
      "epoch 13 | loss: 23.96975| val_rmse: 6.48929 |  0:04:04s                          \n",
      "epoch 14 | loss: 25.26124| val_rmse: 4.71714 |  0:04:21s                          \n",
      "epoch 15 | loss: 23.13638| val_rmse: 5.74685 |  0:04:39s                          \n",
      "epoch 16 | loss: 22.69378| val_rmse: 4.33962 |  0:04:57s                          \n",
      "epoch 17 | loss: 23.38387| val_rmse: 4.54321 |  0:05:14s                          \n",
      "epoch 18 | loss: 23.58579| val_rmse: 5.78279 |  0:05:32s                          \n",
      "epoch 19 | loss: 22.2682 | val_rmse: 4.48685 |  0:05:49s                          \n",
      "epoch 20 | loss: 20.99393| val_rmse: 2.93263 |  0:06:06s                          \n",
      "epoch 21 | loss: 22.77728| val_rmse: 3.22552 |  0:06:24s                          \n",
      "epoch 22 | loss: 22.91459| val_rmse: 5.05786 |  0:06:41s                          \n",
      "epoch 23 | loss: 20.82341| val_rmse: 5.986   |  0:06:58s                          \n",
      "epoch 24 | loss: 21.74623| val_rmse: 3.79391 |  0:07:15s                          \n",
      "epoch 25 | loss: 21.92538| val_rmse: 4.52134 |  0:07:32s                          \n",
      "epoch 26 | loss: 21.36092| val_rmse: 4.752   |  0:07:50s                          \n",
      "epoch 27 | loss: 17.30968| val_rmse: 3.70531 |  0:08:07s                          \n",
      "epoch 28 | loss: 21.86666| val_rmse: 3.1157  |  0:08:24s                          \n",
      "epoch 29 | loss: 21.57306| val_rmse: 5.71332 |  0:08:41s                          \n",
      "epoch 30 | loss: 22.22515| val_rmse: 3.44948 |  0:08:58s                          \n",
      "epoch 31 | loss: 22.78823| val_rmse: 3.28153 |  0:09:15s                          \n",
      "epoch 32 | loss: 23.05853| val_rmse: 4.9147  |  0:09:33s                          \n",
      "epoch 33 | loss: 21.79655| val_rmse: 2.65925 |  0:09:50s                          \n",
      "epoch 34 | loss: 21.33034| val_rmse: 4.519   |  0:10:08s                          \n",
      "epoch 35 | loss: 25.28855| val_rmse: 3.44469 |  0:10:25s                          \n",
      "epoch 36 | loss: 22.0787 | val_rmse: 5.55526 |  0:10:43s                          \n",
      "epoch 37 | loss: 21.55002| val_rmse: 3.3506  |  0:11:00s                          \n",
      "epoch 38 | loss: 21.52829| val_rmse: 4.58067 |  0:11:18s                          \n",
      "epoch 39 | loss: 21.71246| val_rmse: 5.35101 |  0:11:35s                          \n",
      "Stop training because you reached max_epochs = 40 with best_epoch = 33 and best_val_rmse = 2.65925\n",
      " 20%|â–ˆâ–ˆ        | 3/15 [42:55<2:02:55, 614.65s/trial, best loss: 3.907758157350823]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–‹       | 4/15 [42:57<1:58:40, 647.36s/trial, best loss: 3.907758157350823]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 47.72361| val_rmse: 8.78895 |  0:00:14s                          \n",
      "epoch 1  | loss: 35.59987| val_rmse: 8.5928  |  0:00:30s                          \n",
      "epoch 2  | loss: 31.19815| val_rmse: 7.40569 |  0:00:44s                          \n",
      "epoch 3  | loss: 24.21437| val_rmse: 6.51911 |  0:00:59s                          \n",
      "epoch 4  | loss: 24.99306| val_rmse: 7.26319 |  0:01:13s                          \n",
      "epoch 5  | loss: 26.51727| val_rmse: 6.77357 |  0:01:28s                          \n",
      "epoch 6  | loss: 18.43472| val_rmse: 6.95237 |  0:01:42s                          \n",
      "epoch 7  | loss: 23.16714| val_rmse: 4.35847 |  0:01:57s                          \n",
      "epoch 8  | loss: 26.74255| val_rmse: 5.53794 |  0:02:12s                          \n",
      "epoch 9  | loss: 23.98174| val_rmse: 8.57241 |  0:02:27s                          \n",
      "epoch 10 | loss: 21.78472| val_rmse: 3.6876  |  0:02:41s                          \n",
      "epoch 11 | loss: 22.54038| val_rmse: 6.77273 |  0:02:56s                          \n",
      "epoch 12 | loss: 23.16015| val_rmse: 6.39638 |  0:03:11s                          \n",
      "epoch 13 | loss: 22.27086| val_rmse: 4.91455 |  0:03:26s                          \n",
      "epoch 14 | loss: 23.35262| val_rmse: 3.35102 |  0:03:41s                          \n",
      "epoch 15 | loss: 23.91272| val_rmse: 17.99958|  0:03:56s                          \n",
      "epoch 16 | loss: 23.34959| val_rmse: 3.32152 |  0:04:11s                          \n",
      "epoch 17 | loss: 22.35841| val_rmse: 3.72417 |  0:04:25s                          \n",
      "epoch 18 | loss: 21.39731| val_rmse: 6.98516 |  0:04:40s                          \n",
      "epoch 19 | loss: 22.58274| val_rmse: 6.63533 |  0:04:55s                          \n",
      "epoch 20 | loss: 20.95486| val_rmse: 6.53411 |  0:05:10s                          \n",
      "epoch 21 | loss: 21.61074| val_rmse: 6.33614 |  0:05:25s                          \n",
      "epoch 22 | loss: 22.49323| val_rmse: 6.4107  |  0:05:40s                          \n",
      "epoch 23 | loss: 23.7223 | val_rmse: 6.72937 |  0:05:55s                          \n",
      "epoch 24 | loss: 25.54538| val_rmse: 8.64764 |  0:06:10s                          \n",
      "epoch 25 | loss: 23.5879 | val_rmse: 4.64803 |  0:06:24s                          \n",
      "epoch 26 | loss: 20.73068| val_rmse: 3.04524 |  0:06:39s                          \n",
      "epoch 27 | loss: 21.27236| val_rmse: 6.51498 |  0:06:54s                          \n",
      "epoch 28 | loss: 21.0227 | val_rmse: 6.31068 |  0:07:09s                          \n",
      "epoch 29 | loss: 21.86375| val_rmse: 6.99189 |  0:07:23s                          \n",
      "epoch 30 | loss: 21.63172| val_rmse: 3.69177 |  0:07:38s                          \n",
      "epoch 31 | loss: 24.03307| val_rmse: 3.9563  |  0:07:53s                          \n",
      "epoch 32 | loss: 21.95888| val_rmse: 3.06509 |  0:08:07s                          \n",
      "epoch 33 | loss: 20.78662| val_rmse: 4.01378 |  0:08:22s                          \n",
      "epoch 34 | loss: 24.72222| val_rmse: 5.84423 |  0:08:37s                          \n",
      "epoch 35 | loss: 21.59121| val_rmse: 3.74682 |  0:08:52s                          \n",
      "epoch 36 | loss: 21.51603| val_rmse: 7.02823 |  0:09:06s                          \n",
      "epoch 37 | loss: 21.13617| val_rmse: 6.35783 |  0:09:20s                          \n",
      "epoch 38 | loss: 21.01934| val_rmse: 6.26219 |  0:09:35s                          \n",
      "epoch 39 | loss: 19.51291| val_rmse: 5.60705 |  0:09:49s                          \n",
      "Stop training because you reached max_epochs = 40 with best_epoch = 26 and best_val_rmse = 3.04524\n",
      " 27%|â–ˆâ–ˆâ–‹       | 4/15 [52:46<1:58:40, 647.36s/trial, best loss: 3.907758157350823]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [52:48<1:44:28, 626.86s/trial, best loss: 3.907758157350823]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 48.37005| val_rmse: 6.88058 |  0:00:16s                          \n",
      "epoch 1  | loss: 39.22877| val_rmse: 6.7868  |  0:00:32s                          \n",
      "epoch 2  | loss: 38.66765| val_rmse: 6.80709 |  0:00:48s                          \n",
      "epoch 3  | loss: 33.99695| val_rmse: 6.34502 |  0:01:04s                          \n",
      "epoch 4  | loss: 30.51206| val_rmse: 5.53404 |  0:01:20s                          \n",
      "epoch 5  | loss: 25.48104| val_rmse: 4.60912 |  0:01:36s                          \n",
      "epoch 6  | loss: 27.03928| val_rmse: 4.14338 |  0:01:52s                          \n",
      "epoch 7  | loss: 26.70634| val_rmse: 5.93196 |  0:02:09s                          \n",
      "epoch 8  | loss: 22.13003| val_rmse: 6.01376 |  0:02:25s                          \n",
      "epoch 9  | loss: 24.12558| val_rmse: 6.48985 |  0:02:41s                          \n",
      "epoch 10 | loss: 23.47802| val_rmse: 5.22398 |  0:02:57s                          \n",
      "epoch 11 | loss: 19.48212| val_rmse: 6.16928 |  0:03:13s                          \n",
      "epoch 12 | loss: 21.73844| val_rmse: 4.45834 |  0:03:29s                          \n",
      "epoch 13 | loss: 24.41352| val_rmse: 4.24088 |  0:03:46s                          \n",
      "epoch 14 | loss: 22.00977| val_rmse: 4.45182 |  0:04:02s                          \n",
      "epoch 15 | loss: 22.7501 | val_rmse: 3.21735 |  0:04:18s                          \n",
      "epoch 16 | loss: 21.30755| val_rmse: 3.74364 |  0:04:35s                          \n",
      "epoch 17 | loss: 20.32014| val_rmse: 3.08245 |  0:04:50s                          \n",
      "epoch 18 | loss: 20.7763 | val_rmse: 3.4412  |  0:05:06s                          \n",
      "epoch 19 | loss: 19.41534| val_rmse: 4.92359 |  0:05:23s                          \n",
      "epoch 20 | loss: 21.11183| val_rmse: 4.12984 |  0:05:39s                          \n",
      "epoch 21 | loss: 19.39501| val_rmse: 4.26774 |  0:05:55s                          \n",
      "epoch 22 | loss: 19.53964| val_rmse: 3.08254 |  0:06:10s                          \n",
      "epoch 23 | loss: 19.10149| val_rmse: 3.19886 |  0:06:27s                          \n",
      "epoch 24 | loss: 18.73903| val_rmse: 3.84367 |  0:06:43s                          \n",
      "epoch 25 | loss: 18.96897| val_rmse: 4.91302 |  0:06:58s                          \n",
      "epoch 26 | loss: 20.944  | val_rmse: 4.13895 |  0:07:14s                          \n",
      "epoch 27 | loss: 16.61267| val_rmse: 3.05395 |  0:07:31s                            \n",
      "epoch 28 | loss: 18.75088| val_rmse: 3.16534 |  0:07:47s                            \n",
      "epoch 29 | loss: 13.74803| val_rmse: 4.81502 |  0:08:04s                            \n",
      "epoch 30 | loss: 18.06437| val_rmse: 3.47962 |  0:08:20s                            \n",
      "epoch 31 | loss: 19.60355| val_rmse: 3.93855 |  0:08:36s                            \n",
      "epoch 32 | loss: 18.55186| val_rmse: 2.88105 |  0:08:52s                            \n",
      "epoch 33 | loss: 18.92685| val_rmse: 2.70721 |  0:09:09s                            \n",
      "epoch 34 | loss: 19.24988| val_rmse: 4.2879  |  0:09:25s                            \n",
      "epoch 35 | loss: 17.92674| val_rmse: 3.51657 |  0:09:41s                            \n",
      "epoch 36 | loss: 19.2866 | val_rmse: 2.87839 |  0:09:58s                            \n",
      "epoch 37 | loss: 19.98934| val_rmse: 3.54025 |  0:10:13s                            \n",
      "epoch 38 | loss: 18.9438 | val_rmse: 3.20229 |  0:10:29s                            \n",
      "epoch 39 | loss: 17.5562 | val_rmse: 3.44036 |  0:10:45s                            \n",
      "Stop training because you reached max_epochs = 40 with best_epoch = 33 and best_val_rmse = 2.70721\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [1:03:34<1:44:28, 626.86s/trial, best loss: 3.907758157350823]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [1:03:35<1:35:05, 633.94s/trial, best loss: 3.440357728977523]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 46.4163 | val_rmse: 8.66161 |  0:00:17s                            \n",
      "epoch 1  | loss: 45.29433| val_rmse: 7.34849 |  0:00:35s                            \n",
      "epoch 2  | loss: 38.95731| val_rmse: 6.55646 |  0:00:52s                            \n",
      "epoch 3  | loss: 37.22578| val_rmse: 7.45708 |  0:01:10s                            \n",
      "epoch 4  | loss: 34.90919| val_rmse: 7.03933 |  0:01:27s                            \n",
      "epoch 5  | loss: 34.14817| val_rmse: 6.7277  |  0:01:44s                            \n",
      "epoch 6  | loss: 32.60859| val_rmse: 6.43901 |  0:02:01s                            \n",
      "epoch 7  | loss: 34.13007| val_rmse: 5.5476  |  0:02:19s                            \n",
      "epoch 8  | loss: 31.99235| val_rmse: 6.70196 |  0:02:36s                            \n",
      "epoch 9  | loss: 33.59787| val_rmse: 6.12231 |  0:02:53s                            \n",
      "epoch 10 | loss: 31.36766| val_rmse: 7.25693 |  0:03:11s                            \n",
      "epoch 11 | loss: 33.61009| val_rmse: 6.38646 |  0:03:28s                            \n",
      "epoch 12 | loss: 33.36245| val_rmse: 6.48752 |  0:03:46s                            \n",
      "epoch 13 | loss: 33.01162| val_rmse: 5.48544 |  0:04:03s                            \n",
      "epoch 14 | loss: 27.3013 | val_rmse: 5.66228 |  0:04:21s                            \n",
      "epoch 15 | loss: 30.86608| val_rmse: 4.34884 |  0:04:38s                            \n",
      "epoch 16 | loss: 27.68464| val_rmse: 4.1314  |  0:04:56s                            \n",
      "epoch 17 | loss: 26.09982| val_rmse: 3.75417 |  0:05:13s                            \n",
      "epoch 18 | loss: 29.30756| val_rmse: 5.2089  |  0:05:31s                            \n",
      "epoch 19 | loss: 26.24644| val_rmse: 4.02478 |  0:05:48s                            \n",
      "epoch 20 | loss: 27.15443| val_rmse: 6.04334 |  0:06:05s                            \n",
      "epoch 21 | loss: 25.27361| val_rmse: 5.01615 |  0:06:23s                            \n",
      "epoch 22 | loss: 24.45641| val_rmse: 4.2302  |  0:06:41s                            \n",
      "epoch 23 | loss: 25.41466| val_rmse: 3.17057 |  0:06:58s                            \n",
      "epoch 24 | loss: 25.35192| val_rmse: 3.30906 |  0:07:16s                            \n",
      "epoch 25 | loss: 23.10509| val_rmse: 3.08216 |  0:07:33s                            \n",
      "epoch 26 | loss: 23.36191| val_rmse: 3.81388 |  0:07:50s                            \n",
      "epoch 27 | loss: 25.26165| val_rmse: 3.48048 |  0:08:08s                            \n",
      "epoch 28 | loss: 23.41211| val_rmse: 6.98907 |  0:08:25s                            \n",
      "epoch 29 | loss: 23.48238| val_rmse: 5.62044 |  0:08:43s                            \n",
      "epoch 30 | loss: 21.66911| val_rmse: 3.58979 |  0:09:01s                            \n",
      "epoch 31 | loss: 23.30729| val_rmse: 6.0623  |  0:09:18s                            \n",
      "epoch 32 | loss: 22.49161| val_rmse: 4.70815 |  0:09:36s                            \n",
      "epoch 33 | loss: 22.37795| val_rmse: 4.9872  |  0:09:53s                            \n",
      "epoch 34 | loss: 20.28548| val_rmse: 4.38188 |  0:10:10s                            \n",
      "epoch 35 | loss: 22.24624| val_rmse: 3.7154  |  0:10:28s                            \n",
      "epoch 36 | loss: 20.42654| val_rmse: 3.88959 |  0:10:46s                            \n",
      "epoch 37 | loss: 21.20645| val_rmse: 3.7291  |  0:11:03s                            \n",
      "epoch 38 | loss: 23.72481| val_rmse: 3.06794 |  0:11:21s                            \n",
      "epoch 39 | loss: 20.28024| val_rmse: 5.19272 |  0:11:38s                            \n",
      "Stop training because you reached max_epochs = 40 with best_epoch = 38 and best_val_rmse = 3.06794\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [1:15:14<1:35:05, 633.94s/trial, best loss: 3.440357728977523]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [1:15:16<1:27:27, 655.90s/trial, best loss: 3.440357728977523]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 40.72873| val_rmse: 7.07804 |  0:00:15s                            \n",
      "epoch 1  | loss: 33.73166| val_rmse: 6.90429 |  0:00:30s                            \n",
      "epoch 2  | loss: 32.44822| val_rmse: 6.76643 |  0:00:45s                            \n",
      "epoch 3  | loss: 30.18685| val_rmse: 6.02545 |  0:01:00s                            \n",
      "epoch 4  | loss: 31.92297| val_rmse: 5.66758 |  0:01:15s                            \n",
      "epoch 5  | loss: 27.68958| val_rmse: 6.12627 |  0:01:30s                            \n",
      "epoch 6  | loss: 30.41017| val_rmse: 5.99964 |  0:01:45s                            \n",
      "epoch 7  | loss: 24.43928| val_rmse: 5.01848 |  0:02:00s                            \n",
      "epoch 8  | loss: 24.78031| val_rmse: 6.00547 |  0:02:14s                            \n",
      "epoch 9  | loss: 25.25455| val_rmse: 4.83962 |  0:02:28s                            \n",
      "epoch 10 | loss: 22.70502| val_rmse: 4.8294  |  0:02:43s                            \n",
      "epoch 11 | loss: 24.10798| val_rmse: 5.02326 |  0:02:58s                            \n",
      "epoch 12 | loss: 22.20328| val_rmse: 3.54025 |  0:03:13s                            \n",
      "epoch 13 | loss: 20.40192| val_rmse: 3.25771 |  0:03:28s                            \n",
      "epoch 14 | loss: 21.22735| val_rmse: 3.15663 |  0:03:43s                            \n",
      "epoch 15 | loss: 19.92144| val_rmse: 3.33466 |  0:03:58s                            \n",
      "epoch 16 | loss: 18.21089| val_rmse: 3.33896 |  0:04:13s                            \n",
      "epoch 17 | loss: 21.45916| val_rmse: 4.68236 |  0:04:27s                            \n",
      "epoch 18 | loss: 19.46973| val_rmse: 3.86048 |  0:04:42s                            \n",
      "epoch 19 | loss: 17.1927 | val_rmse: 3.09946 |  0:04:57s                            \n",
      "epoch 20 | loss: 19.36876| val_rmse: 3.4985  |  0:05:12s                            \n",
      "epoch 21 | loss: 18.32401| val_rmse: 3.80449 |  0:05:27s                            \n",
      "epoch 22 | loss: 17.45596| val_rmse: 3.43113 |  0:05:42s                            \n",
      "epoch 23 | loss: 17.0549 | val_rmse: 4.00879 |  0:05:56s                            \n",
      "epoch 24 | loss: 16.93489| val_rmse: 3.45727 |  0:06:12s                            \n",
      "epoch 25 | loss: 17.70388| val_rmse: 3.86346 |  0:06:27s                            \n",
      "epoch 26 | loss: 18.77572| val_rmse: 3.24907 |  0:06:42s                            \n",
      "epoch 27 | loss: 18.02911| val_rmse: 3.10932 |  0:06:57s                            \n",
      "epoch 28 | loss: 17.42454| val_rmse: 3.50706 |  0:07:09s                            \n",
      "epoch 29 | loss: 18.9939 | val_rmse: 3.38128 |  0:07:23s                            \n",
      "epoch 30 | loss: 16.99215| val_rmse: 3.24074 |  0:07:36s                            \n",
      "epoch 31 | loss: 17.50778| val_rmse: 3.46197 |  0:07:49s                            \n",
      "epoch 32 | loss: 17.25387| val_rmse: 3.47727 |  0:08:02s                            \n",
      "epoch 33 | loss: 17.4401 | val_rmse: 3.15771 |  0:08:15s                            \n",
      "epoch 34 | loss: 19.62393| val_rmse: 3.78314 |  0:08:28s                            \n",
      "                                                                                    \n",
      "Early stopping occurred at epoch 34 with best_epoch = 19 and best_val_rmse = 3.09946\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [1:23:45<1:27:27, 655.90s/trial, best loss: 3.440357728977523]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [1:23:46<1:11:05, 609.42s/trial, best loss: 3.440357728977523]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 41.9324 | val_rmse: 7.35828 |  0:00:15s                            \n",
      "epoch 1  | loss: 42.47064| val_rmse: 7.28254 |  0:00:32s                            \n",
      "epoch 2  | loss: 40.87052| val_rmse: 6.98802 |  0:00:47s                            \n",
      "epoch 3  | loss: 38.65668| val_rmse: 7.32098 |  0:01:03s                            \n",
      "epoch 4  | loss: 38.37262| val_rmse: 7.02017 |  0:01:19s                            \n",
      "epoch 5  | loss: 38.7854 | val_rmse: 6.7361  |  0:01:35s                            \n",
      "epoch 6  | loss: 37.87817| val_rmse: 6.85647 |  0:01:50s                            \n",
      "epoch 7  | loss: 32.34219| val_rmse: 5.78783 |  0:02:06s                            \n",
      "epoch 8  | loss: 27.93181| val_rmse: 5.78574 |  0:02:22s                            \n",
      "epoch 9  | loss: 25.57796| val_rmse: 5.66175 |  0:02:37s                            \n",
      "epoch 10 | loss: 25.20907| val_rmse: 6.38491 |  0:02:53s                            \n",
      "epoch 11 | loss: 26.18397| val_rmse: 5.79197 |  0:03:09s                            \n",
      "epoch 12 | loss: 26.10727| val_rmse: 5.18166 |  0:03:24s                            \n",
      "epoch 13 | loss: 26.30285| val_rmse: 4.82193 |  0:03:40s                            \n",
      "epoch 14 | loss: 26.28086| val_rmse: 6.46628 |  0:03:55s                            \n",
      "epoch 15 | loss: 24.20056| val_rmse: 9.15367 |  0:04:10s                            \n",
      "epoch 16 | loss: 23.49117| val_rmse: 6.92829 |  0:04:26s                            \n",
      "epoch 17 | loss: 25.03156| val_rmse: 5.19941 |  0:04:41s                            \n",
      "epoch 18 | loss: 23.92247| val_rmse: 6.90359 |  0:04:57s                            \n",
      "epoch 19 | loss: 21.8605 | val_rmse: 4.38864 |  0:05:12s                            \n",
      "epoch 20 | loss: 22.82893| val_rmse: 3.68942 |  0:05:28s                            \n",
      "epoch 21 | loss: 19.90225| val_rmse: 6.51128 |  0:05:44s                            \n",
      "epoch 22 | loss: 24.72011| val_rmse: 6.48256 |  0:05:59s                            \n",
      "epoch 23 | loss: 24.13464| val_rmse: 4.34799 |  0:06:15s                            \n",
      "epoch 24 | loss: 23.09061| val_rmse: 4.41744 |  0:06:30s                            \n",
      "epoch 25 | loss: 21.35911| val_rmse: 5.03499 |  0:06:46s                            \n",
      "epoch 26 | loss: 22.44539| val_rmse: 5.17358 |  0:07:02s                            \n",
      "epoch 27 | loss: 24.17741| val_rmse: 5.56138 |  0:07:17s                            \n",
      "epoch 28 | loss: 24.25188| val_rmse: 4.89594 |  0:07:32s                            \n",
      "epoch 29 | loss: 23.2485 | val_rmse: 5.31744 |  0:07:48s                            \n",
      "epoch 30 | loss: 21.46605| val_rmse: 4.94925 |  0:08:03s                            \n",
      "epoch 31 | loss: 27.29316| val_rmse: 3.99607 |  0:08:19s                            \n",
      "epoch 32 | loss: 24.5744 | val_rmse: 4.08617 |  0:08:34s                            \n",
      "epoch 33 | loss: 26.42286| val_rmse: 3.19415 |  0:08:50s                            \n",
      "epoch 34 | loss: 23.92534| val_rmse: 3.74014 |  0:09:05s                            \n",
      "epoch 35 | loss: 22.7395 | val_rmse: 5.29041 |  0:09:21s                            \n",
      "epoch 36 | loss: 24.13051| val_rmse: 4.31351 |  0:09:36s                            \n",
      "epoch 37 | loss: 25.37045| val_rmse: 4.99938 |  0:09:52s                            \n",
      "epoch 38 | loss: 22.74213| val_rmse: 3.39921 |  0:10:07s                            \n",
      "epoch 39 | loss: 22.4092 | val_rmse: 3.18448 |  0:10:23s                            \n",
      "Stop training because you reached max_epochs = 40 with best_epoch = 39 and best_val_rmse = 3.18448\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [1:34:10<1:11:05, 609.42s/trial, best loss: 3.440357728977523]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [1:34:12<1:01:26, 614.42s/trial, best loss: 3.184476332710138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 48.7147 | val_rmse: 9.6567  |  0:00:14s                            \n",
      "epoch 1  | loss: 41.94994| val_rmse: 7.28022 |  0:00:28s                            \n",
      "epoch 2  | loss: 37.38236| val_rmse: 7.29872 |  0:00:43s                            \n",
      "epoch 3  | loss: 36.50275| val_rmse: 7.24035 |  0:00:57s                            \n",
      "epoch 4  | loss: 36.22497| val_rmse: 7.01771 |  0:01:12s                            \n",
      "epoch 5  | loss: 36.05574| val_rmse: 5.70319 |  0:01:26s                            \n",
      "epoch 6  | loss: 30.57688| val_rmse: 7.25905 |  0:01:40s                            \n",
      "epoch 7  | loss: 26.73726| val_rmse: 7.77247 |  0:01:55s                            \n",
      "epoch 8  | loss: 30.05554| val_rmse: 6.71503 |  0:02:10s                            \n",
      "epoch 9  | loss: 29.27158| val_rmse: 6.41209 |  0:02:24s                            \n",
      "epoch 10 | loss: 31.1797 | val_rmse: 6.50188 |  0:02:38s                            \n",
      "epoch 11 | loss: 29.22611| val_rmse: 5.56091 |  0:02:53s                            \n",
      "epoch 12 | loss: 29.02655| val_rmse: 7.3401  |  0:03:07s                            \n",
      "epoch 13 | loss: 31.27147| val_rmse: 7.70933 |  0:03:21s                            \n",
      "epoch 14 | loss: 29.18299| val_rmse: 6.92477 |  0:03:35s                            \n",
      "epoch 15 | loss: 28.83208| val_rmse: 5.52583 |  0:03:50s                            \n",
      "epoch 16 | loss: 27.47218| val_rmse: 5.88544 |  0:04:05s                            \n",
      "epoch 17 | loss: 26.8197 | val_rmse: 5.48588 |  0:04:19s                            \n",
      "epoch 18 | loss: 26.77414| val_rmse: 6.45183 |  0:04:33s                            \n",
      "epoch 19 | loss: 27.27629| val_rmse: 5.45889 |  0:04:48s                            \n",
      "epoch 20 | loss: 29.83168| val_rmse: 5.91682 |  0:05:02s                            \n",
      "epoch 21 | loss: 28.22206| val_rmse: 6.76052 |  0:05:17s                            \n",
      "epoch 22 | loss: 28.70811| val_rmse: 5.81607 |  0:05:31s                            \n",
      "epoch 23 | loss: 29.6283 | val_rmse: 12.93534|  0:05:46s                            \n",
      "epoch 24 | loss: 30.57265| val_rmse: 5.56556 |  0:06:00s                            \n",
      "epoch 25 | loss: 28.20817| val_rmse: 6.17355 |  0:06:15s                            \n",
      "epoch 26 | loss: 32.89378| val_rmse: 7.73182 |  0:06:29s                            \n",
      "epoch 27 | loss: 29.39112| val_rmse: 5.16873 |  0:06:44s                            \n",
      "epoch 28 | loss: 29.45584| val_rmse: 4.45402 |  0:06:58s                            \n",
      "epoch 29 | loss: 27.02493| val_rmse: 6.90502 |  0:07:12s                            \n",
      "epoch 30 | loss: 28.13379| val_rmse: 6.26763 |  0:07:27s                            \n",
      "epoch 31 | loss: 28.33126| val_rmse: 5.31527 |  0:07:41s                            \n",
      "epoch 32 | loss: 27.00937| val_rmse: 5.74074 |  0:07:56s                            \n",
      "epoch 33 | loss: 26.77001| val_rmse: 5.63209 |  0:08:10s                            \n",
      "epoch 34 | loss: 27.71751| val_rmse: 7.63814 |  0:08:25s                            \n",
      "epoch 35 | loss: 33.18344| val_rmse: 8.81132 |  0:08:39s                            \n",
      "epoch 36 | loss: 28.7528 | val_rmse: 6.44198 |  0:08:53s                            \n",
      "epoch 37 | loss: 27.30257| val_rmse: 4.928   |  0:09:08s                            \n",
      "epoch 38 | loss: 29.60438| val_rmse: 5.4083  |  0:09:22s                            \n",
      "epoch 39 | loss: 27.81253| val_rmse: 6.68562 |  0:09:37s                            \n",
      "Stop training because you reached max_epochs = 40 with best_epoch = 28 and best_val_rmse = 4.45402\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [1:43:49<1:01:26, 614.42s/trial, best loss: 3.184476332710138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [1:43:51<50:17, 603.45s/trial, best loss: 3.184476332710138] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 45.70389| val_rmse: 7.1332  |  0:00:14s                           \n",
      "epoch 1  | loss: 36.74465| val_rmse: 6.80873 |  0:00:28s                           \n",
      "epoch 2  | loss: 37.56989| val_rmse: 7.17225 |  0:00:43s                           \n",
      "epoch 3  | loss: 35.45186| val_rmse: 6.85704 |  0:00:57s                           \n",
      "epoch 4  | loss: 35.30896| val_rmse: 6.44631 |  0:01:11s                           \n",
      "epoch 5  | loss: 32.4373 | val_rmse: 5.72573 |  0:01:25s                           \n",
      "epoch 6  | loss: 31.47191| val_rmse: 6.72299 |  0:01:40s                           \n",
      "epoch 7  | loss: 33.73331| val_rmse: 6.10194 |  0:01:54s                           \n",
      "epoch 8  | loss: 33.75272| val_rmse: 5.70478 |  0:02:08s                           \n",
      "epoch 9  | loss: 27.65723| val_rmse: 4.68454 |  0:02:22s                           \n",
      "epoch 10 | loss: 26.65429| val_rmse: 5.18918 |  0:02:37s                           \n",
      "epoch 11 | loss: 26.03271| val_rmse: 4.31829 |  0:02:51s                           \n",
      "epoch 12 | loss: 23.8188 | val_rmse: 5.28022 |  0:03:06s                           \n",
      "epoch 13 | loss: 23.64738| val_rmse: 4.25852 |  0:03:20s                           \n",
      "epoch 14 | loss: 24.76387| val_rmse: 4.3383  |  0:03:34s                           \n",
      "epoch 15 | loss: 23.74926| val_rmse: 4.43064 |  0:03:49s                           \n",
      "epoch 16 | loss: 23.32498| val_rmse: 3.6995  |  0:04:03s                           \n",
      "epoch 17 | loss: 23.43856| val_rmse: 4.56235 |  0:04:18s                           \n",
      "epoch 18 | loss: 20.72329| val_rmse: 3.88062 |  0:04:32s                           \n",
      "epoch 19 | loss: 20.67922| val_rmse: 3.89913 |  0:04:46s                           \n",
      "epoch 20 | loss: 21.00797| val_rmse: 4.43487 |  0:05:01s                           \n",
      "epoch 21 | loss: 20.6046 | val_rmse: 3.88376 |  0:05:15s                           \n",
      "epoch 22 | loss: 21.1237 | val_rmse: 4.09205 |  0:05:29s                           \n",
      "epoch 23 | loss: 20.15053| val_rmse: 3.8619  |  0:05:44s                           \n",
      "epoch 24 | loss: 19.82989| val_rmse: 3.27049 |  0:05:58s                           \n",
      "epoch 25 | loss: 21.40607| val_rmse: 4.00699 |  0:06:13s                           \n",
      "epoch 26 | loss: 20.30102| val_rmse: 3.83562 |  0:06:27s                           \n",
      "epoch 27 | loss: 19.24841| val_rmse: 3.2315  |  0:06:42s                           \n",
      "epoch 28 | loss: 20.22819| val_rmse: 3.6391  |  0:06:56s                           \n",
      "epoch 29 | loss: 19.87815| val_rmse: 3.76547 |  0:07:10s                           \n",
      "epoch 30 | loss: 21.31497| val_rmse: 3.95786 |  0:07:25s                           \n",
      "epoch 31 | loss: 20.80666| val_rmse: 3.23804 |  0:07:39s                           \n",
      "epoch 32 | loss: 18.87319| val_rmse: 3.93209 |  0:07:53s                           \n",
      "epoch 33 | loss: 19.92014| val_rmse: 3.57892 |  0:08:08s                           \n",
      "epoch 34 | loss: 18.04317| val_rmse: 4.07611 |  0:08:22s                           \n",
      "epoch 35 | loss: 18.53421| val_rmse: 3.17998 |  0:08:37s                           \n",
      "epoch 36 | loss: 19.03431| val_rmse: 3.39728 |  0:08:51s                           \n",
      "epoch 37 | loss: 19.13051| val_rmse: 3.29046 |  0:09:06s                           \n",
      "epoch 38 | loss: 18.51035| val_rmse: 3.14095 |  0:09:20s                           \n",
      "epoch 39 | loss: 19.42259| val_rmse: 3.69757 |  0:09:34s                           \n",
      "Stop training because you reached max_epochs = 40 with best_epoch = 38 and best_val_rmse = 3.14095\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [1:53:26<50:17, 603.45s/trial, best loss: 3.184476332710138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [1:53:27<39:41, 595.28s/trial, best loss: 3.184476332710138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 45.61532| val_rmse: 7.42332 |  0:00:14s                           \n",
      "epoch 1  | loss: 40.39279| val_rmse: 7.32526 |  0:00:28s                           \n",
      "epoch 2  | loss: 31.56296| val_rmse: 7.52681 |  0:00:43s                           \n",
      "epoch 3  | loss: 29.16207| val_rmse: 7.30151 |  0:00:57s                           \n",
      "epoch 4  | loss: 27.81351| val_rmse: 7.27463 |  0:01:11s                           \n",
      "epoch 5  | loss: 25.8471 | val_rmse: 7.1475  |  0:01:26s                           \n",
      "epoch 6  | loss: 29.04041| val_rmse: 7.38143 |  0:01:40s                           \n",
      "epoch 7  | loss: 27.13556| val_rmse: 6.35913 |  0:01:54s                           \n",
      "epoch 8  | loss: 24.69711| val_rmse: 4.35939 |  0:02:09s                           \n",
      "epoch 9  | loss: 25.0018 | val_rmse: 6.48669 |  0:02:23s                           \n",
      "epoch 10 | loss: 27.2824 | val_rmse: 8.18886 |  0:02:38s                           \n",
      "epoch 11 | loss: 29.28252| val_rmse: 6.5383  |  0:02:52s                           \n",
      "epoch 12 | loss: 28.21625| val_rmse: 3.55481 |  0:03:07s                           \n",
      "epoch 13 | loss: 26.82383| val_rmse: 5.89484 |  0:03:21s                           \n",
      "epoch 14 | loss: 26.70292| val_rmse: 5.9216  |  0:03:36s                           \n",
      "epoch 15 | loss: 26.43605| val_rmse: 7.41204 |  0:03:50s                           \n",
      "epoch 16 | loss: 19.89407| val_rmse: 6.4218  |  0:04:04s                           \n",
      "epoch 17 | loss: 30.28407| val_rmse: 15.51305|  0:04:19s                           \n",
      "epoch 18 | loss: 28.90034| val_rmse: 3.75743 |  0:04:33s                           \n",
      "epoch 19 | loss: 26.67224| val_rmse: 5.97966 |  0:04:48s                           \n",
      "epoch 20 | loss: 27.06357| val_rmse: 6.11287 |  0:05:02s                           \n",
      "epoch 21 | loss: 24.86858| val_rmse: 5.97282 |  0:05:16s                           \n",
      "epoch 22 | loss: 28.95266| val_rmse: 7.66706 |  0:05:31s                           \n",
      "epoch 23 | loss: 26.98179| val_rmse: 8.37417 |  0:05:45s                           \n",
      "epoch 24 | loss: 24.1244 | val_rmse: 6.76992 |  0:05:59s                           \n",
      "epoch 25 | loss: 25.23843| val_rmse: 6.10851 |  0:06:14s                           \n",
      "epoch 26 | loss: 25.96616| val_rmse: 7.31166 |  0:06:28s                           \n",
      "epoch 27 | loss: 23.57035| val_rmse: 4.45432 |  0:06:43s                           \n",
      "                                                                                   \n",
      "Early stopping occurred at epoch 27 with best_epoch = 12 and best_val_rmse = 3.55481\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [2:00:11<39:41, 595.28s/trial, best loss: 3.184476332710138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [2:00:13<26:52, 537.54s/trial, best loss: 3.184476332710138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 46.87481| val_rmse: 7.45206 |  0:00:17s                           \n",
      "epoch 1  | loss: 38.98568| val_rmse: 6.84612 |  0:00:33s                           \n",
      "epoch 2  | loss: 33.16784| val_rmse: 6.92544 |  0:00:50s                           \n",
      "epoch 3  | loss: 31.02076| val_rmse: 6.74913 |  0:01:07s                           \n",
      "epoch 4  | loss: 26.4053 | val_rmse: 7.19159 |  0:01:24s                           \n",
      "epoch 5  | loss: 25.834  | val_rmse: 6.77086 |  0:01:41s                           \n",
      "epoch 6  | loss: 27.3046 | val_rmse: 6.02683 |  0:01:57s                           \n",
      "epoch 7  | loss: 26.87679| val_rmse: 6.65814 |  0:02:14s                           \n",
      "epoch 8  | loss: 24.75146| val_rmse: 6.0266  |  0:02:31s                           \n",
      "epoch 9  | loss: 26.18322| val_rmse: 6.09102 |  0:02:48s                           \n",
      "epoch 10 | loss: 25.06315| val_rmse: 7.40076 |  0:03:05s                           \n",
      "epoch 11 | loss: 19.14066| val_rmse: 7.25169 |  0:03:21s                           \n",
      "epoch 12 | loss: 31.47612| val_rmse: 13.89128|  0:03:38s                           \n",
      "epoch 13 | loss: 25.91947| val_rmse: 5.89822 |  0:03:55s                           \n",
      "epoch 14 | loss: 24.57475| val_rmse: 6.62291 |  0:04:12s                           \n",
      "epoch 15 | loss: 27.49983| val_rmse: 6.66447 |  0:04:28s                           \n",
      "epoch 16 | loss: 28.31956| val_rmse: 6.4141  |  0:04:45s                           \n",
      "epoch 17 | loss: 24.92808| val_rmse: 4.3348  |  0:05:02s                           \n",
      "epoch 18 | loss: 27.78487| val_rmse: 4.81054 |  0:05:19s                           \n",
      "epoch 19 | loss: 26.6892 | val_rmse: 6.15503 |  0:05:36s                           \n",
      "epoch 20 | loss: 25.04683| val_rmse: 7.73547 |  0:05:52s                           \n",
      "epoch 21 | loss: 25.53166| val_rmse: 6.20108 |  0:06:09s                           \n",
      "epoch 22 | loss: 24.8016 | val_rmse: 7.116   |  0:06:26s                           \n",
      "epoch 23 | loss: 30.23529| val_rmse: 3.86691 |  0:06:42s                           \n",
      "epoch 24 | loss: 29.88377| val_rmse: 11.34072|  0:06:59s                           \n",
      "epoch 25 | loss: 26.52188| val_rmse: 5.57054 |  0:07:16s                           \n",
      "epoch 26 | loss: 26.37755| val_rmse: 5.63175 |  0:07:33s                           \n",
      "epoch 27 | loss: 24.68839| val_rmse: 5.9513  |  0:07:49s                           \n",
      "epoch 28 | loss: 26.41858| val_rmse: 7.15407 |  0:08:06s                           \n",
      "epoch 29 | loss: 26.12928| val_rmse: 6.07192 |  0:08:23s                           \n",
      "epoch 30 | loss: 25.4828 | val_rmse: 3.83489 |  0:08:40s                           \n",
      "epoch 31 | loss: 26.08951| val_rmse: 7.6036  |  0:08:56s                           \n",
      "epoch 32 | loss: 23.95578| val_rmse: 7.17665 |  0:09:13s                           \n",
      "epoch 33 | loss: 25.66091| val_rmse: 6.23624 |  0:09:29s                           \n",
      "epoch 34 | loss: 23.25856| val_rmse: 4.70902 |  0:09:46s                           \n",
      "epoch 35 | loss: 28.75002| val_rmse: 3.9074  |  0:10:03s                           \n",
      "epoch 36 | loss: 22.80086| val_rmse: 3.7465  |  0:10:20s                           \n",
      "epoch 37 | loss: 23.47389| val_rmse: 7.01648 |  0:10:37s                           \n",
      "epoch 38 | loss: 25.5686 | val_rmse: 3.91986 |  0:10:54s                           \n",
      "epoch 39 | loss: 25.3487 | val_rmse: 5.21482 |  0:11:14s                           \n",
      "Stop training because you reached max_epochs = 40 with best_epoch = 36 and best_val_rmse = 3.7465\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [2:11:27<26:52, 537.54s/trial, best loss: 3.184476332710138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [2:11:30<19:19, 579.83s/trial, best loss: 3.184476332710138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 44.68319| val_rmse: 7.09161 |  0:00:15s                           \n",
      "epoch 1  | loss: 35.32821| val_rmse: 7.12368 |  0:00:31s                           \n",
      "epoch 2  | loss: 36.8371 | val_rmse: 7.21936 |  0:00:47s                           \n",
      "epoch 3  | loss: 32.17844| val_rmse: 6.76721 |  0:01:02s                           \n",
      "epoch 4  | loss: 27.67533| val_rmse: 5.21716 |  0:01:18s                           \n",
      "epoch 5  | loss: 29.03589| val_rmse: 7.14165 |  0:01:33s                           \n",
      "epoch 6  | loss: 27.76353| val_rmse: 6.67806 |  0:01:49s                           \n",
      "epoch 7  | loss: 25.68824| val_rmse: 5.21645 |  0:02:05s                           \n",
      "epoch 8  | loss: 22.38087| val_rmse: 6.2421  |  0:02:20s                           \n",
      "epoch 9  | loss: 22.42354| val_rmse: 5.6841  |  0:02:36s                           \n",
      "epoch 10 | loss: 22.26186| val_rmse: 5.02439 |  0:02:52s                           \n",
      "epoch 11 | loss: 26.70617| val_rmse: 4.72539 |  0:03:07s                           \n",
      "epoch 12 | loss: 24.75702| val_rmse: 5.54175 |  0:03:23s                           \n",
      "epoch 13 | loss: 24.6866 | val_rmse: 5.52653 |  0:03:39s                           \n",
      "epoch 14 | loss: 22.66586| val_rmse: 5.85899 |  0:03:54s                           \n",
      "epoch 15 | loss: 22.26909| val_rmse: 5.03222 |  0:04:10s                           \n",
      "epoch 16 | loss: 23.60838| val_rmse: 3.1325  |  0:04:25s                           \n",
      "epoch 17 | loss: 22.90071| val_rmse: 4.7651  |  0:04:41s                           \n",
      "epoch 18 | loss: 23.01963| val_rmse: 4.95384 |  0:04:56s                           \n",
      "epoch 19 | loss: 20.89206| val_rmse: 4.70738 |  0:05:12s                           \n",
      "epoch 20 | loss: 20.82542| val_rmse: 5.1275  |  0:05:28s                           \n",
      "epoch 21 | loss: 21.93333| val_rmse: 4.56921 |  0:05:43s                           \n",
      "epoch 22 | loss: 25.09566| val_rmse: 4.62262 |  0:05:59s                           \n",
      "epoch 23 | loss: 24.65557| val_rmse: 4.6112  |  0:06:15s                           \n",
      "epoch 24 | loss: 22.5357 | val_rmse: 3.6798  |  0:06:30s                           \n",
      "epoch 25 | loss: 20.4338 | val_rmse: 3.55584 |  0:06:46s                           \n",
      "epoch 26 | loss: 19.91549| val_rmse: 4.43564 |  0:07:01s                           \n",
      "epoch 27 | loss: 21.01375| val_rmse: 4.10761 |  0:07:17s                           \n",
      "epoch 28 | loss: 20.07011| val_rmse: 4.42839 |  0:07:33s                           \n",
      "epoch 29 | loss: 22.28601| val_rmse: 3.99052 |  0:07:48s                           \n",
      "epoch 30 | loss: 22.13582| val_rmse: 4.23779 |  0:08:04s                           \n",
      "epoch 31 | loss: 18.99398| val_rmse: 5.44296 |  0:08:19s                           \n",
      "                                                                                   \n",
      "Early stopping occurred at epoch 31 with best_epoch = 16 and best_val_rmse = 3.1325\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [2:19:50<19:19, 579.83s/trial, best loss: 3.184476332710138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [2:19:52<09:16, 556.28s/trial, best loss: 3.184476332710138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 45.58073| val_rmse: 7.1364  |  0:00:13s                           \n",
      "epoch 1  | loss: 37.74866| val_rmse: 6.50126 |  0:00:25s                           \n",
      "epoch 2  | loss: 31.62779| val_rmse: 6.75511 |  0:00:38s                           \n",
      "epoch 3  | loss: 30.85029| val_rmse: 6.48796 |  0:00:51s                           \n",
      "epoch 4  | loss: 26.15702| val_rmse: 6.54951 |  0:01:04s                           \n",
      "epoch 5  | loss: 24.53813| val_rmse: 7.20062 |  0:01:17s                           \n",
      "epoch 6  | loss: 23.09699| val_rmse: 6.05022 |  0:01:30s                           \n",
      "epoch 7  | loss: 22.73302| val_rmse: 5.73868 |  0:01:43s                           \n",
      "epoch 8  | loss: 22.79028| val_rmse: 6.20147 |  0:01:56s                           \n",
      "epoch 9  | loss: 21.28281| val_rmse: 5.99148 |  0:02:09s                           \n",
      "epoch 10 | loss: 22.45807| val_rmse: 5.34003 |  0:02:22s                           \n",
      "epoch 11 | loss: 21.40658| val_rmse: 5.36677 |  0:02:35s                           \n",
      "epoch 12 | loss: 21.439  | val_rmse: 5.00544 |  0:02:48s                           \n",
      "epoch 13 | loss: 18.9585 | val_rmse: 4.49895 |  0:03:01s                           \n",
      "epoch 14 | loss: 21.96902| val_rmse: 5.0671  |  0:03:14s                           \n",
      "epoch 15 | loss: 20.26229| val_rmse: 5.09535 |  0:03:27s                           \n",
      "epoch 16 | loss: 21.34701| val_rmse: 4.00808 |  0:03:40s                           \n",
      "epoch 17 | loss: 18.83938| val_rmse: 4.8567  |  0:03:53s                           \n",
      "epoch 18 | loss: 19.64508| val_rmse: 4.42996 |  0:04:06s                           \n",
      "epoch 19 | loss: 21.14283| val_rmse: 4.46065 |  0:04:19s                           \n",
      "epoch 20 | loss: 18.36174| val_rmse: 4.08582 |  0:04:33s                           \n",
      "epoch 21 | loss: 18.77638| val_rmse: 4.60398 |  0:04:46s                           \n",
      "epoch 22 | loss: 18.33115| val_rmse: 4.84052 |  0:05:00s                           \n",
      "epoch 23 | loss: 20.17158| val_rmse: 4.79114 |  0:05:13s                           \n",
      "epoch 24 | loss: 20.00702| val_rmse: 3.40789 |  0:05:26s                           \n",
      "epoch 25 | loss: 19.89178| val_rmse: 3.48807 |  0:05:39s                           \n",
      "epoch 26 | loss: 20.05365| val_rmse: 4.41488 |  0:05:53s                           \n",
      "epoch 27 | loss: 19.5986 | val_rmse: 4.13134 |  0:06:06s                           \n",
      "epoch 28 | loss: 19.89469| val_rmse: 3.50776 |  0:06:19s                           \n",
      "epoch 29 | loss: 18.82734| val_rmse: 4.03647 |  0:06:32s                           \n",
      "epoch 30 | loss: 20.36201| val_rmse: 4.128   |  0:06:45s                           \n",
      "epoch 31 | loss: 17.62478| val_rmse: 3.14362 |  0:06:58s                           \n",
      "epoch 32 | loss: 20.23948| val_rmse: 5.28369 |  0:07:11s                           \n",
      "epoch 33 | loss: 18.72674| val_rmse: 4.13895 |  0:07:24s                           \n",
      "epoch 34 | loss: 21.27497| val_rmse: 4.80797 |  0:07:37s                           \n",
      "epoch 35 | loss: 19.76257| val_rmse: 3.75651 |  0:07:50s                           \n",
      "epoch 36 | loss: 18.11743| val_rmse: 3.30074 |  0:08:03s                           \n",
      "epoch 37 | loss: 18.91379| val_rmse: 2.96095 |  0:08:17s                           \n",
      "epoch 38 | loss: 19.99258| val_rmse: 3.0225  |  0:08:30s                           \n",
      "epoch 39 | loss: 19.67634| val_rmse: 3.42994 |  0:08:43s                           \n",
      "Stop training because you reached max_epochs = 40 with best_epoch = 37 and best_val_rmse = 2.96095\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [2:28:35<09:16, 556.28s/trial, best loss: 3.184476332710138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rma81\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [2:28:36<00:00, 594.46s/trial, best loss: 3.184476332710138]\n",
      "Best hyperparameters: {'gamma': np.float64(1.5494371504360784), 'lambda_sparse': np.float64(0.021527849243156594), 'lr': np.float64(0.037088099470451996), 'n_a': np.float64(48.0), 'n_d': np.float64(32.0), 'n_steps': np.float64(8.0), 'weight_decay': np.float64(0.16622206018645966)}\n"
     ]
    }
   ],
   "source": [
    "def objective(params):\n",
    "    # Extract hyperparameters\n",
    "    n_d = int(params['n_d'])\n",
    "    n_a = int(params['n_a'])\n",
    "    n_steps = int(params['n_steps'])\n",
    "    gamma = params['gamma']\n",
    "    lambda_sparse = params['lambda_sparse']\n",
    "    lr = params['lr']\n",
    "    weight_decay = params['weight_decay']\n",
    "    \n",
    "    # Initialize TabNet model with current hyperparameters\n",
    "    tabNetModel = TabNetRegressor(\n",
    "        n_d=n_d,            \n",
    "        n_a=n_a,             \n",
    "        n_steps=n_steps,     \n",
    "        gamma=gamma,         \n",
    "        lambda_sparse=lambda_sparse,\n",
    "        optimizer_fn=torch.optim.AdamW,\n",
    "        optimizer_params=dict(lr=lr, weight_decay=weight_decay),\n",
    "        scheduler_params={\"step_size\":8, \"gamma\":0.9},\n",
    "        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "        mask_type=\"entmax\",\n",
    "    )\n",
    "    \n",
    "    # Train the model and get validation loss (e.g., RMSE)\n",
    "    tabNetModel.fit(\n",
    "        X_train=X_train, \n",
    "        y_train=y_train.reshape(-1, 1),\n",
    "        eval_set=[(X_test, y_test.reshape(-1, 1))],\n",
    "        eval_name=['val'],\n",
    "        eval_metric=['rmse'],\n",
    "        max_epochs=40,\n",
    "        patience=15,\n",
    "        batch_size=64,\n",
    "        virtual_batch_size=32,\n",
    "        num_workers=3,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    # Extract validation RMSE (or any other metric you prefer)\n",
    "    val_rmse = tabNetModel.history.history['val_rmse'][-1]  # Get the last RMSE value\n",
    "    return val_rmse\n",
    "\n",
    "# Define the search space\n",
    "space = {\n",
    "    'n_d': hp.quniform('n_d', 8, 64, 16),          # Number of decision units\n",
    "    'n_a': hp.quniform('n_a', 8, 64, 16),          # Number of attention units\n",
    "    'n_steps': hp.quniform('n_steps', 3, 10, 2),   # Number of steps in TabNet\n",
    "    'gamma': hp.uniform('gamma', 1.0, 2.0),        # Sparsity controlling factor\n",
    "    'lambda_sparse': hp.loguniform('lambda_sparse', -5, -1),  # Sparsity regularization term\n",
    "    'lr': hp.loguniform('lr', -5, -1),             # Learning rate (log scale)\n",
    "    'weight_decay': hp.loguniform('weight_decay', -5, -1)  # Weight decay (log scale)\n",
    "}\n",
    "\n",
    "# Initialize Trials object to store results\n",
    "trials = Trials()\n",
    "\n",
    "# Run the optimization with Hyperopt\n",
    "best = fmin(\n",
    "    fn=objective,             # Objective function\n",
    "    space=space,              # Search space\n",
    "    algo=tpe.suggest,         # Optimization algorithm (Tree of Parzen Estimators)\n",
    "    max_evals=15,             # Number of evaluations\n",
    "    trials=trials             # Store trials\n",
    ")\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best hyperparameters:\", best)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
