{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression,Ridge\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error,r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "from pre_processing import preprocess_data\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    dataset = pd.read_excel(r\"globalterrorismdb_2021Jan-June_1222dist.xlsx\") # 2021-2021 June\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success</th>\n",
       "      <th>gname_freq</th>\n",
       "      <th>city_freq</th>\n",
       "      <th>country_freq</th>\n",
       "      <th>attacktype1_score</th>\n",
       "      <th>targtype1_score</th>\n",
       "      <th>weaptype1_score</th>\n",
       "      <th>gname_score</th>\n",
       "      <th>country_score</th>\n",
       "      <th>city_score</th>\n",
       "      <th>...</th>\n",
       "      <th>nkill_likelihood_score</th>\n",
       "      <th>region_3</th>\n",
       "      <th>region_5</th>\n",
       "      <th>region_6</th>\n",
       "      <th>region_8</th>\n",
       "      <th>region_9</th>\n",
       "      <th>region_10</th>\n",
       "      <th>region_11</th>\n",
       "      <th>region_12</th>\n",
       "      <th>nkill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.167228</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.121429</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.096521</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.159371</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.121429</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.096521</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.093154</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   success  gname_freq  city_freq  country_freq  attacktype1_score  \\\n",
       "0      1.0    0.228571   0.066667      0.167228              0.875   \n",
       "1      1.0    0.121429   0.033333      0.096521              0.500   \n",
       "2      1.0    0.000000   0.033333      0.159371              0.875   \n",
       "3      1.0    0.121429   0.033333      0.096521              0.875   \n",
       "4      1.0    0.000000   0.033333      0.093154              0.875   \n",
       "\n",
       "   targtype1_score  weaptype1_score  gname_score  country_score  city_score  \\\n",
       "0         1.000000         0.857143     0.977778       0.948718    0.123077   \n",
       "1         0.842105         0.857143     0.911111       0.871795    0.030769   \n",
       "2         0.894737         0.857143     0.000000       0.641026    0.015385   \n",
       "3         0.894737         0.857143     0.911111       0.871795    0.092308   \n",
       "4         1.000000         0.857143     0.022222       0.743590    0.030769   \n",
       "\n",
       "   ...  nkill_likelihood_score  region_3  region_5  region_6  region_8  \\\n",
       "0  ...                0.589934       0.0       0.0       0.0       0.0   \n",
       "1  ...                0.347526       0.0       0.0       0.0       0.0   \n",
       "2  ...                0.477050       0.0       0.0       1.0       0.0   \n",
       "3  ...                0.503175       0.0       0.0       0.0       0.0   \n",
       "4  ...                0.543654       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   region_9  region_10  region_11  region_12  nkill  \n",
       "0       0.0        1.0        0.0        0.0    5.0  \n",
       "1       0.0        0.0        1.0        0.0    1.0  \n",
       "2       0.0        0.0        0.0        0.0    0.0  \n",
       "3       0.0        0.0        1.0        0.0    6.0  \n",
       "4       0.0        1.0        0.0        0.0    1.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_data()\n",
    "X, y, dataset = preprocess_data(dataset)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) MLP\n",
    "## Hyperparameter Tuning and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TerrorismDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1 = 128, hidden_dim2 = 64, dropout_rate = 0.2, activation_function='ELU'):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        if activation_function == 'ReLU':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation_function == 'ELU':\n",
    "            self.activation = nn.ELU()\n",
    "        elif activation_function == 'LeakyReLU':\n",
    "            self.activation = nn.LeakyReLU()\n",
    "            \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.fc3 = nn.Linear(hidden_dim2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 55. Best RMSE: 6.3904          \n",
      "Early stopping at epoch 101. Best RMSE: 7.0760                                   \n",
      "Early stopping at epoch 164. Best RMSE: 3.3805                                   \n",
      "Early stopping at epoch 117. Best RMSE: 7.4871                                   \n",
      "Early stopping at epoch 122. Best RMSE: 3.4562                                  \n",
      "Early stopping at epoch 51. Best RMSE: 6.6373                                   \n",
      "Early stopping at epoch 53. Best RMSE: 4.9789                                   \n",
      "Early stopping at epoch 118. Best RMSE: 6.4934                                  \n",
      "Early stopping at epoch 61. Best RMSE: 4.4675                                   \n",
      "Early stopping at epoch 82. Best RMSE: 4.8670                                   \n",
      "Early stopping at epoch 67. Best RMSE: 4.4131                                    \n",
      "Early stopping at epoch 90. Best RMSE: 4.9318                                    \n",
      "Early stopping at epoch 165. Best RMSE: 3.3290                                   \n",
      "Early stopping at epoch 60. Best RMSE: 4.8541                                     \n",
      "Early stopping at epoch 111. Best RMSE: 3.1882                                    \n",
      "Early stopping at epoch 178. Best RMSE: 3.0613                                    \n",
      "Early stopping at epoch 85. Best RMSE: 4.0951                                     \n",
      "Early stopping at epoch 189. Best RMSE: 3.5059                                    \n",
      "Early stopping at epoch 95. Best RMSE: 3.2549                                     \n",
      "Early stopping at epoch 150. Best RMSE: 4.6690                                    \n",
      "Early stopping at epoch 140. Best RMSE: 3.0891                                    \n",
      "Early stopping at epoch 198. Best RMSE: 2.9603                                    \n",
      "Early stopping at epoch 248. Best RMSE: 2.9056                                    \n",
      "Early stopping at epoch 151. Best RMSE: 2.9874                                     \n",
      "Early stopping at epoch 91. Best RMSE: 3.0918                                      \n",
      "Early stopping at epoch 142. Best RMSE: 2.8422                                     \n",
      "Early stopping at epoch 136. Best RMSE: 2.8164                                      \n",
      "Early stopping at epoch 132. Best RMSE: 2.8836                                      \n",
      "Early stopping at epoch 79. Best RMSE: 3.6171                                      \n",
      "Early stopping at epoch 90. Best RMSE: 5.2479                                      \n",
      "Early stopping at epoch 63. Best RMSE: 4.6517                                      \n",
      "Early stopping at epoch 137. Best RMSE: 3.1714                                     \n",
      "Early stopping at epoch 184. Best RMSE: 3.8806                                     \n",
      "Early stopping at epoch 70. Best RMSE: 3.5077                                      \n",
      "Early stopping at epoch 98. Best RMSE: 3.2688                                      \n",
      "Early stopping at epoch 300. Best RMSE: 3.9022                                     \n",
      "Early stopping at epoch 191. Best RMSE: 3.0580                                     \n",
      "Early stopping at epoch 79. Best RMSE: 4.6983                                      \n",
      "Early stopping at epoch 52. Best RMSE: 5.2940                                      \n",
      "Early stopping at epoch 78. Best RMSE: 7.2504                                      \n",
      "Early stopping at epoch 64. Best RMSE: 3.5304                                      \n",
      "Early stopping at epoch 105. Best RMSE: 3.1398                                     \n",
      "Early stopping at epoch 116. Best RMSE: 7.3890                                   \n",
      "Early stopping at epoch 168. Best RMSE: 3.9096                                   \n",
      "Early stopping at epoch 71. Best RMSE: 4.6285                                      \n",
      "Early stopping at epoch 66. Best RMSE: 4.3866                                      \n",
      "Early stopping at epoch 170. Best RMSE: 3.0481                                     \n",
      "Early stopping at epoch 170. Best RMSE: 3.0181                                     \n",
      "Early stopping at epoch 109. Best RMSE: 3.5842                                     \n",
      "Early stopping at epoch 51. Best RMSE: 5.8600                                      \n",
      "Early stopping at epoch 144. Best RMSE: 3.1487                                     \n",
      "Early stopping at epoch 59. Best RMSE: 6.8923                                      \n",
      "Early stopping at epoch 85. Best RMSE: 4.0262                                      \n",
      "Early stopping at epoch 196. Best RMSE: 2.9611                                     \n",
      "Early stopping at epoch 93. Best RMSE: 2.9991                                      \n",
      "Early stopping at epoch 104. Best RMSE: 3.1885                                     \n",
      "Early stopping at epoch 68. Best RMSE: 5.1976                                      \n",
      "Early stopping at epoch 100. Best RMSE: 2.8506                                   \n",
      "Early stopping at epoch 284. Best RMSE: 3.9293                                   \n",
      "Early stopping at epoch 179. Best RMSE: 3.2472                                     \n",
      "Early stopping at epoch 67. Best RMSE: 3.9702                                      \n",
      "Early stopping at epoch 161. Best RMSE: 3.2868                                   \n",
      "Early stopping at epoch 208. Best RMSE: 3.4782                                   \n",
      "Early stopping at epoch 144. Best RMSE: 2.9140                                   \n",
      "Early stopping at epoch 64. Best RMSE: 4.1454                                    \n",
      "Early stopping at epoch 104. Best RMSE: 3.0331                                   \n",
      "Early stopping at epoch 56. Best RMSE: 4.7200                                    \n",
      "Early stopping at epoch 185. Best RMSE: 2.9567                                   \n",
      "Early stopping at epoch 206. Best RMSE: 3.1137                                   \n",
      "Early stopping at epoch 166. Best RMSE: 2.9623                                     \n",
      "Early stopping at epoch 132. Best RMSE: 3.0423                                     \n",
      "Early stopping at epoch 131. Best RMSE: 2.9946                                     \n",
      "Early stopping at epoch 206. Best RMSE: 2.9490                                   \n",
      "Early stopping at epoch 111. Best RMSE: 3.1125                                     \n",
      "Early stopping at epoch 65. Best RMSE: 3.7768                                      \n",
      "Early stopping at epoch 109. Best RMSE: 2.9122                                   \n",
      "Early stopping at epoch 74. Best RMSE: 3.8181                                    \n",
      "Early stopping at epoch 130. Best RMSE: 2.9656                                   \n",
      "Early stopping at epoch 198. Best RMSE: 2.9926                                   \n",
      "Early stopping at epoch 91. Best RMSE: 5.0854                                    \n",
      "Early stopping at epoch 163. Best RMSE: 2.8945                                   \n",
      "Early stopping at epoch 80. Best RMSE: 4.3642                                    \n",
      "Early stopping at epoch 184. Best RMSE: 3.6606                                   \n",
      "Early stopping at epoch 58. Best RMSE: 4.2758                                    \n",
      "Early stopping at epoch 131. Best RMSE: 3.0267                                   \n",
      "Early stopping at epoch 165. Best RMSE: 2.9885                                   \n",
      "Early stopping at epoch 61. Best RMSE: 5.6906                                    \n",
      "Early stopping at epoch 143. Best RMSE: 3.1884                                   \n",
      "Early stopping at epoch 106. Best RMSE: 3.9487                                   \n",
      "Early stopping at epoch 178. Best RMSE: 3.5025                                   \n",
      "Early stopping at epoch 183. Best RMSE: 2.8386                                   \n",
      "Early stopping at epoch 165. Best RMSE: 2.7757                                   \n",
      "Early stopping at epoch 323. Best RMSE: 3.7628                                   \n",
      "Early stopping at epoch 116. Best RMSE: 2.9590                                     \n",
      "Early stopping at epoch 139. Best RMSE: 3.5832                                     \n",
      "Early stopping at epoch 165. Best RMSE: 3.3935                                   \n",
      "Early stopping at epoch 107. Best RMSE: 3.0502                                   \n",
      "Early stopping at epoch 197. Best RMSE: 2.9327                                   \n",
      "Early stopping at epoch 190. Best RMSE: 2.9736                                   \n",
      "Early stopping at epoch 117. Best RMSE: 3.6923                                   \n",
      "Early stopping at epoch 115. Best RMSE: 2.9229                                    \n",
      "Early stopping at epoch 84. Best RMSE: 2.9139                                     \n",
      "Early stopping at epoch 130. Best RMSE: 3.0355                                    \n",
      "Early stopping at epoch 132. Best RMSE: 2.8738                                    \n",
      "Early stopping at epoch 176. Best RMSE: 3.1425                                    \n",
      "Early stopping at epoch 162. Best RMSE: 2.9518                                    \n",
      "Early stopping at epoch 69. Best RMSE: 5.9024                                     \n",
      "Early stopping at epoch 126. Best RMSE: 4.7718                                    \n",
      "Early stopping at epoch 106. Best RMSE: 3.5003                                    \n",
      "Early stopping at epoch 67. Best RMSE: 3.9347                                     \n",
      "Early stopping at epoch 139. Best RMSE: 3.1993                                    \n",
      "Early stopping at epoch 152. Best RMSE: 3.1671                                    \n",
      "Early stopping at epoch 129. Best RMSE: 3.2493                                    \n",
      "Early stopping at epoch 197. Best RMSE: 2.8601                                    \n",
      "Early stopping at epoch 71. Best RMSE: 5.2196                                     \n",
      "Early stopping at epoch 168. Best RMSE: 3.4402                                    \n",
      "Early stopping at epoch 74. Best RMSE: 4.0389                                     \n",
      "Early stopping at epoch 163. Best RMSE: 4.4588                                    \n",
      "Early stopping at epoch 89. Best RMSE: 3.0448                                     \n",
      "Early stopping at epoch 59. Best RMSE: 4.0118                                     \n",
      "Early stopping at epoch 233. Best RMSE: 3.0148                                    \n",
      "Early stopping at epoch 138. Best RMSE: 2.9065                                    \n",
      "Early stopping at epoch 242. Best RMSE: 4.4583                                    \n",
      "Early stopping at epoch 109. Best RMSE: 3.6657                                    \n",
      "Early stopping at epoch 123. Best RMSE: 2.9801                                    \n",
      "Early stopping at epoch 130. Best RMSE: 3.3608                                    \n",
      "Early stopping at epoch 219. Best RMSE: 3.4371                                    \n",
      "Early stopping at epoch 107. Best RMSE: 5.2111                                    \n",
      "Early stopping at epoch 128. Best RMSE: 3.1315                                    \n",
      "Early stopping at epoch 76. Best RMSE: 3.6731                                     \n",
      "Early stopping at epoch 148. Best RMSE: 3.1373                                    \n",
      "Early stopping at epoch 255. Best RMSE: 2.8770                                    \n",
      "Early stopping at epoch 99. Best RMSE: 3.7860                                     \n",
      "Early stopping at epoch 176. Best RMSE: 3.5769                                    \n",
      "Early stopping at epoch 156. Best RMSE: 2.8547                                    \n",
      "Early stopping at epoch 136. Best RMSE: 2.8137                                    \n",
      "Early stopping at epoch 54. Best RMSE: 4.3999                                     \n",
      "Early stopping at epoch 59. Best RMSE: 4.4514                                     \n",
      "Early stopping at epoch 130. Best RMSE: 3.0354                                    \n",
      "Early stopping at epoch 151. Best RMSE: 3.0362                                    \n",
      "Early stopping at epoch 124. Best RMSE: 3.6092                                    \n",
      "Early stopping at epoch 101. Best RMSE: 3.6957                                    \n",
      "Early stopping at epoch 125. Best RMSE: 3.4485                                    \n",
      "Early stopping at epoch 57. Best RMSE: 3.9402                                     \n",
      "Early stopping at epoch 64. Best RMSE: 3.7891                                     \n",
      "Early stopping at epoch 140. Best RMSE: 2.9623                                    \n",
      "Early stopping at epoch 190. Best RMSE: 2.8437                                    \n",
      "Early stopping at epoch 95. Best RMSE: 3.0084                                     \n",
      "Early stopping at epoch 70. Best RMSE: 7.4569                                     \n",
      "Early stopping at epoch 180. Best RMSE: 3.0700                                    \n",
      "Early stopping at epoch 179. Best RMSE: 2.8170                                    \n",
      "Early stopping at epoch 113. Best RMSE: 3.0178                                    \n",
      "Early stopping at epoch 138. Best RMSE: 2.8975                                    \n",
      "Early stopping at epoch 133. Best RMSE: 2.9127                                    \n",
      "Early stopping at epoch 125. Best RMSE: 3.0977                                    \n",
      "Early stopping at epoch 227. Best RMSE: 2.9162                                      \n",
      "Early stopping at epoch 266. Best RMSE: 2.7874                                      \n",
      "Early stopping at epoch 181. Best RMSE: 2.8469                                      \n",
      "Early stopping at epoch 198. Best RMSE: 2.8457                                      \n",
      "Early stopping at epoch 198. Best RMSE: 2.9795                                      \n",
      "Early stopping at epoch 103. Best RMSE: 3.0450                                      \n",
      "Early stopping at epoch 142. Best RMSE: 2.9213                                      \n",
      "Early stopping at epoch 242. Best RMSE: 2.7771                                      \n",
      "Early stopping at epoch 267. Best RMSE: 2.7924                                      \n",
      "Early stopping at epoch 161. Best RMSE: 2.9346                                      \n",
      "Early stopping at epoch 149. Best RMSE: 2.8800                                      \n",
      "Early stopping at epoch 296. Best RMSE: 3.0176                                      \n",
      "Early stopping at epoch 171. Best RMSE: 2.9244                                      \n",
      "Early stopping at epoch 153. Best RMSE: 3.2123                                      \n",
      "Early stopping at epoch 264. Best RMSE: 2.8676                                      \n",
      "Early stopping at epoch 222. Best RMSE: 2.7608                                      \n",
      "Early stopping at epoch 185. Best RMSE: 2.9405                                       \n",
      "Early stopping at epoch 172. Best RMSE: 2.8117                                       \n",
      "Early stopping at epoch 225. Best RMSE: 3.3496                                       \n",
      "Early stopping at epoch 155. Best RMSE: 2.8693                                       \n",
      "Early stopping at epoch 187. Best RMSE: 2.9437                                       \n",
      "Early stopping at epoch 108. Best RMSE: 2.9701                                       \n",
      "Early stopping at epoch 211. Best RMSE: 3.0451                                       \n",
      "Early stopping at epoch 126. Best RMSE: 2.9058                                       \n",
      "Early stopping at epoch 116. Best RMSE: 2.9704                                       \n",
      "Early stopping at epoch 138. Best RMSE: 4.6508                                       \n",
      "Early stopping at epoch 92. Best RMSE: 3.0501                                        \n",
      "Early stopping at epoch 95. Best RMSE: 5.5687                                        \n",
      "Early stopping at epoch 87. Best RMSE: 4.6205                                        \n",
      "Early stopping at epoch 164. Best RMSE: 4.3578                                       \n",
      "Early stopping at epoch 107. Best RMSE: 3.0583                                       \n",
      "Early stopping at epoch 78. Best RMSE: 5.1298                                        \n",
      "Early stopping at epoch 135. Best RMSE: 3.0953                                       \n",
      "Early stopping at epoch 178. Best RMSE: 2.8818                                       \n",
      "Early stopping at epoch 262. Best RMSE: 2.8015                                       \n",
      "Early stopping at epoch 164. Best RMSE: 2.9752                                       \n",
      "Early stopping at epoch 220. Best RMSE: 3.4702                                       \n",
      "Early stopping at epoch 127. Best RMSE: 2.9387                                       \n",
      "Early stopping at epoch 73. Best RMSE: 3.9804                                        \n",
      "Early stopping at epoch 136. Best RMSE: 3.0121                                       \n",
      "Early stopping at epoch 78. Best RMSE: 3.3165                                        \n",
      "Early stopping at epoch 127. Best RMSE: 2.8747                                       \n",
      "Early stopping at epoch 165. Best RMSE: 3.8352                                       \n",
      "Early stopping at epoch 176. Best RMSE: 2.8023                                       \n",
      "Early stopping at epoch 183. Best RMSE: 2.8578                                       \n",
      "100%|██████████| 200/200 [1:23:21<00:00, 25.01s/trial, best loss: 2.7608463764190674]\n",
      "Best hyperparameters found: {'activation_function': np.int64(2), 'dropout_rate': np.float64(0.10807216645021676), 'hidden_dim1': np.float64(224.0), 'hidden_dim2': np.float64(64.0), 'lr': np.float64(0.006764759536499616), 'weight_decay': np.float64(0.015068138384218187)}\n"
     ]
    }
   ],
   "source": [
    "# Convert to Dataset and DataLoader\n",
    "train_dataset = TerrorismDataset(X_train, y_train)\n",
    "test_dataset = TerrorismDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=500, lr=0.005, weight_decay=1e-4, patience=15):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    best_rmse = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training Loop with Early Stopping\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for X_train, y_train in train_loader:\n",
    "            X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train)\n",
    "            loss = criterion(outputs, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation Step\n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "                val_outputs = model(X_val)\n",
    "                val_preds.extend(val_outputs.cpu().numpy())\n",
    "                val_labels.extend(y_val.cpu().numpy())\n",
    "\n",
    "        # Calculate RMSE\n",
    "        val_rmse = np.sqrt(np.mean((np.array(val_preds) - np.array(val_labels)) ** 2))\n",
    "\n",
    "        # Early Stopping Check\n",
    "        if val_rmse < best_rmse:\n",
    "            best_rmse = val_rmse\n",
    "            patience_counter = 0  # Reset patience counter\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}. Best RMSE: {best_rmse:.4f}\")\n",
    "            break\n",
    "\n",
    "    return best_rmse\n",
    "\n",
    "def objective(params):\n",
    "    hidden_dim1 = int(params['hidden_dim1'])\n",
    "    hidden_dim2 = int(params['hidden_dim2'])\n",
    "    dropout_rate = params['dropout_rate']\n",
    "    lr = params['lr']\n",
    "    weight_decay = params['weight_decay']\n",
    "    activation_function = params['activation_function']\n",
    "\n",
    "    # Initialize the model with the current hyperparameters\n",
    "    model = MLP(input_dim=X_train.shape[1],\n",
    "                hidden_dim1=hidden_dim1,\n",
    "                hidden_dim2=hidden_dim2,\n",
    "                activation_function= activation_function,\n",
    "                dropout_rate=dropout_rate).to(device)\n",
    "\n",
    "    # Train the model and get validation RMSE\n",
    "    val_rmse = train_model(model, train_loader, val_loader, num_epochs=500, patience = 50,  lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    return val_rmse  # Minimizing the RMSE loss\n",
    "\n",
    "# Define the search space\n",
    "space = {\n",
    "    'hidden_dim1': hp.quniform('hidden_dim1', 32, 512, 16),\n",
    "    'hidden_dim2': hp.quniform('hidden_dim2', 16, 256, 16),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.5),\n",
    "    'lr': hp.loguniform('lr', -5, -1),\n",
    "    'weight_decay': hp.loguniform('weight_decay', -5, -1),\n",
    "    'activation_function': hp.choice('activation_function', ['ReLU', 'ELU', 'LeakyReLU'])\n",
    "\n",
    "}\n",
    "\n",
    "# Initialize Trials object to store results\n",
    "trials = Trials()\n",
    "\n",
    "# Run the optimization\n",
    "best_params = fmin(\n",
    "    fn=objective,             # Objective function\n",
    "    space=space,              # Search space\n",
    "    algo=tpe.suggest,         # Optimization algorithm\n",
    "    max_evals=200,             # Number of evaluations\n",
    "    trials=trials             # Store trials\n",
    ")\n",
    "\n",
    "print(\"Best hyperparameters found:\", best_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
